{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a750d8",
   "metadata": {},
   "source": [
    "Ki·ªÉm tra DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c80e80ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29000/29000 [00:00<00:00, 41725.92it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29000/29000 [00:01<00:00, 28154.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 29000\n",
      "Vocab EN size: 5893\n",
      "Vocab FR size: 6470\n",
      "SRC shape: torch.Size([4, 17])\n",
      "TRG shape: torch.Size([4, 18])\n",
      "SRC example: tensor([   1,   16,   24,   15,   25,  774,   17,   57,   80,  202, 1305,    5,\n",
      "           2,    0,    0,    0,    0])\n",
      "TRG example: tensor([   1,   21,   81,   32,  214,   28,   88,   70,    7, 1171,    5,    2,\n",
      "           0,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.data import get_loader, load_vocab, load_dataset\n",
    "\n",
    "# Load DataLoader\n",
    "train_loader, train_dataset = get_loader(\"data/train.en.gz\", \"data/train.fr.gz\", batch_size=4, shuffle=False)\n",
    "\n",
    "print(f\"Dataset size: {len(train_dataset)}\")\n",
    "print(f\"Vocab EN size: {len(train_dataset.src_vocab.stoi)}\")\n",
    "print(f\"Vocab FR size: {len(train_dataset.trg_vocab.stoi)}\")\n",
    "\n",
    "# Ki·ªÉm tra batch ƒë·∫ßu ti√™n\n",
    "for src, trg in train_loader:\n",
    "    print(\"SRC shape:\", src.shape)  # [batch_size, seq_len]\n",
    "    print(\"TRG shape:\", trg.shape)\n",
    "    print(\"SRC example:\", src[0])\n",
    "    print(\"TRG example:\", trg[0])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a83f7",
   "metadata": {},
   "source": [
    "Test vi·ªác l∆∞u v√† load file vocab, train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eac0aa",
   "metadata": {},
   "source": [
    "Quy t·∫Øc gi·ªõi h·∫°n vocab\n",
    "  - Ch·ªçn ch·ªâ gi·ªØ N t·ª´ ph·ªï bi·∫øn nh·∫•t,\n",
    "  - Ho·∫∑c l·ªçc theo t·∫ßn su·∫•t t·ªëi thi·ªÉu (v√≠ d·ª•: ch·ªâ gi·ªØ c√°c t·ª´ xu·∫•t hi·ªán ‚â• 2 l·∫ßn).\n",
    "\n",
    "Qu√° tr√¨nh t·ªïng qu√°t:\n",
    "  - ƒê·∫øm to√†n b·ªô t·ª´ trong t·∫≠p d·ªØ li·ªáu.\n",
    "  - T√≠nh t·∫ßn su·∫•t xu·∫•t hi·ªán.\n",
    "  - Lo·∫°i b·ªè t·ª´ hi·∫øm (v√≠ d·ª•: freq < 5).\n",
    "  - Gi·ªØ l·∫°i c√°c t·ª´ ph·ªï bi·∫øn nh·∫•t (·ªü ƒë√¢y: ~5.9k cho EN, ~6.4k cho FR).\n",
    "  - Th√™m 4 token ƒë·∫∑c bi·ªát v√†o ƒë·∫ßu (<pad>, <sos>, <eos>, <unk>).\n",
    "  - T·∫°o mapping word ‚Üí index v√† index ‚Üí word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173f9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import Counter\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca2300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ T·ªïng s·ªë c√¢u: 29,000\n",
      "üìä ƒê·ªô d√†i c√¢u:\n",
      "   Trung b√¨nh: 13.11 t·ª´ / c√¢u\n",
      "   Ng·∫Øn nh·∫•t:  4 t·ª´\n",
      "   D√†i nh·∫•t:   41 t·ª´\n",
      "üß† T·ªïng s·ªë t·ª´ Ti·∫øng anh kh√°c nhau (unique words): 9,793\n",
      "\n",
      "üîù 20 t·ª´ ti·∫øng anh ph·ªï bi·∫øn nh·∫•t:\n",
      "a          ‚Üí 49165\n",
      ".          ‚Üí 27623\n",
      "in         ‚Üí 14886\n",
      "the        ‚Üí 10955\n",
      "on         ‚Üí 8035\n",
      "man        ‚Üí 7781\n",
      "is         ‚Üí 7525\n",
      "and        ‚Üí 7379\n",
      "of         ‚Üí 6871\n",
      "with       ‚Üí 6179\n",
      "woman      ‚Üí 3973\n",
      ",          ‚Üí 3963\n",
      "two        ‚Üí 3886\n",
      "are        ‚Üí 3717\n",
      "to         ‚Üí 3128\n",
      "people     ‚Üí 3122\n",
      "at         ‚Üí 2927\n",
      "an         ‚Üí 2861\n",
      "wearing    ‚Üí 2623\n",
      "shirt      ‚Üí 2324\n",
      "S·ªë t·ª´ ch·ªâ xu·∫•t hi·ªán 1 l·∫ßn: 3904\n",
      "T·ª∑ l·ªá t·ª´ hi·∫øm: 39.87%\n"
     ]
    }
   ],
   "source": [
    "# === Th·ªëng k√™ d·ªØ li·ªáu ti·∫øng Anh trong t·∫≠p train.en.gz ===\n",
    "\n",
    "# D√πng spaCy ƒë·ªÉ tokenize ti·∫øng Anh\n",
    "spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text.lower() for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "# ======= ƒê·ªçc file train.en ho·∫∑c train.en.gz =======\n",
    "file_path = \"data/train.en.gz\"\n",
    "\n",
    "if file_path.endswith(\".gz\"):\n",
    "    with gzip.open(file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read().strip().split(\"\\n\")\n",
    "else:\n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        lines = f.read().strip().split(\"\\n\")\n",
    "\n",
    "print(f\"‚úÖ T·ªïng s·ªë c√¢u: {len(lines):,}\")\n",
    "\n",
    "# ======= Tokenize to√†n b·ªô t·∫≠p =======\n",
    "tokenized_sentences = [tokenize_en(line) for line in lines]\n",
    "\n",
    "# ƒê·∫øm s·ªë t·ª´ trong t·ª´ng c√¢u\n",
    "sentence_lengths = [len(sent) for sent in tokenized_sentences]\n",
    "\n",
    "# T·ªïng h·ª£p th·ªëng k√™ ƒë·ªô d√†i c√¢u\n",
    "avg_len = sum(sentence_lengths) / len(sentence_lengths)\n",
    "max_len = max(sentence_lengths)\n",
    "min_len = min(sentence_lengths)\n",
    "\n",
    "print(f\"üìä ƒê·ªô d√†i c√¢u:\")\n",
    "print(f\"   Trung b√¨nh: {avg_len:.2f} t·ª´ / c√¢u\")\n",
    "print(f\"   Ng·∫Øn nh·∫•t:  {min_len} t·ª´\")\n",
    "print(f\"   D√†i nh·∫•t:   {max_len} t·ª´\")\n",
    "\n",
    "# ======= Th·ªëng k√™ t·ª´ v·ª±ng =======\n",
    "word_freq = Counter([word for sent in tokenized_sentences for word in sent])\n",
    "\n",
    "unique_words = len(word_freq)\n",
    "print(f\"üß† T·ªïng s·ªë t·ª´ Ti·∫øng anh kh√°c nhau (unique words): {unique_words:,}\")\n",
    "\n",
    "# Hi·ªÉn th·ªã 20 t·ª´ ph·ªï bi·∫øn nh·∫•t\n",
    "print(\"\\nüîù 20 t·ª´ ti·∫øng anh ph·ªï bi·∫øn nh·∫•t:\")\n",
    "for word, freq in word_freq.most_common(20):\n",
    "    print(f\"{word:10s} ‚Üí {freq}\")\n",
    "rare_words = [w for w, f in word_freq.items() if f == 1]\n",
    "print(f\"S·ªë t·ª´ ch·ªâ xu·∫•t hi·ªán 1 l·∫ßn: {len(rare_words)}\")\n",
    "print(f\"T·ª∑ l·ªá t·ª´ hi·∫øm: {len(rare_words)/len(word_freq)*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d49033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ T·ªïng s·ªë c√¢u: 29,000\n",
      "üìä ƒê·ªô d√†i c√¢u:\n",
      "   Trung b√¨nh: 14.28 t·ª´ / c√¢u\n",
      "   Ng·∫Øn nh·∫•t:  4 t·ª´\n",
      "   D√†i nh·∫•t:   54 t·ª´\n",
      "üß† T·ªïng s·ªë t·ª´ Ti·∫øng ph√°p kh√°c nhau (unique words): 11,149\n",
      "\n",
      "üîù 20 t·ª´ ti·∫øng ph√°p ph·ªï bi·∫øn nh·∫•t:\n",
      "un         ‚Üí 34942\n",
      ".          ‚Üí 27680\n",
      "une        ‚Üí 20624\n",
      "de         ‚Üí 14013\n",
      "en         ‚Üí 9866\n",
      "d'         ‚Üí 8139\n",
      "dans       ‚Üí 8059\n",
      "sur        ‚Üí 7957\n",
      "homme      ‚Üí 7887\n",
      "et         ‚Üí 7426\n",
      "des        ‚Üí 7406\n",
      "avec       ‚Üí 7177\n",
      "la         ‚Üí 5651\n",
      "√†          ‚Üí 5326\n",
      ",          ‚Üí 4800\n",
      "femme      ‚Üí 4454\n",
      "l'         ‚Üí 4284\n",
      "deux       ‚Üí 4068\n",
      "le         ‚Üí 3699\n",
      "est        ‚Üí 3257\n",
      "S·ªë t·ª´ ch·ªâ xu·∫•t hi·ªán 1 l·∫ßn: 4683\n",
      "T·ª∑ l·ªá t·ª´ hi·∫øm: 42.00%\n"
     ]
    }
   ],
   "source": [
    "#  Th·ªëng k√™ d·ªØ li·ªáu ti·∫øng Ph√°p trong t·∫≠p train.fr.gz\n",
    "import gzip\n",
    "from collections import Counter\n",
    "import spacy\n",
    "\n",
    "# D√πng spaCy ƒë·ªÉ tokenize ti·∫øng Anh\n",
    "spacy_fr = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "def tokenize_fr(text):\n",
    "    return [tok.text.lower() for tok in spacy_fr.tokenizer(text)]\n",
    "\n",
    "# ======= ƒê·ªçc file train.en ho·∫∑c train.en.gz =======\n",
    "file_path = \"data/train.fr.gz\"\n",
    "\n",
    "if file_path.endswith(\".gz\"):\n",
    "    with gzip.open(file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read().strip().split(\"\\n\")\n",
    "else:\n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        lines = f.read().strip().split(\"\\n\")\n",
    "\n",
    "print(f\"‚úÖ T·ªïng s·ªë c√¢u: {len(lines):,}\")\n",
    "\n",
    "# ======= Tokenize to√†n b·ªô t·∫≠p =======\n",
    "tokenized_sentences = [tokenize_fr(line) for line in lines]\n",
    "\n",
    "# ƒê·∫øm s·ªë t·ª´ trong t·ª´ng c√¢u\n",
    "sentence_lengths = [len(sent) for sent in tokenized_sentences]\n",
    "\n",
    "# T·ªïng h·ª£p th·ªëng k√™ ƒë·ªô d√†i c√¢u\n",
    "avg_len = sum(sentence_lengths) / len(sentence_lengths)\n",
    "max_len = max(sentence_lengths)\n",
    "min_len = min(sentence_lengths)\n",
    "\n",
    "print(f\"üìä ƒê·ªô d√†i c√¢u:\")\n",
    "print(f\"   Trung b√¨nh: {avg_len:.2f} t·ª´ / c√¢u\")\n",
    "print(f\"   Ng·∫Øn nh·∫•t:  {min_len} t·ª´\")\n",
    "print(f\"   D√†i nh·∫•t:   {max_len} t·ª´\")\n",
    "\n",
    "# ======= Th·ªëng k√™ t·ª´ v·ª±ng =======\n",
    "word_freq = Counter([word for sent in tokenized_sentences for word in sent])\n",
    "\n",
    "unique_words = len(word_freq)\n",
    "print(f\"üß† T·ªïng s·ªë t·ª´ Ti·∫øng ph√°p kh√°c nhau (unique words): {unique_words:,}\")\n",
    "\n",
    "# Hi·ªÉn th·ªã 20 t·ª´ ph·ªï bi·∫øn nh·∫•t\n",
    "print(\"\\nüîù 20 t·ª´ ti·∫øng ph√°p ph·ªï bi·∫øn nh·∫•t:\")\n",
    "for word, freq in word_freq.most_common(20):\n",
    "    print(f\"{word:10s} ‚Üí {freq}\")\n",
    "rare_words = [w for w, f in word_freq.items() if f == 1]\n",
    "print(f\"S·ªë t·ª´ ch·ªâ xu·∫•t hi·ªán 1 l·∫ßn: {len(rare_words)}\")\n",
    "print(f\"T·ª∑ l·ªá t·ª´ hi·∫øm: {len(rare_words)/len(word_freq)*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59da0bd9",
   "metadata": {},
   "source": [
    "Ti·∫øng Ph√°p (French)\n",
    "  + S·ªë t·ª´ xu·∫•t hi·ªán duy nh·∫•t (unique) ng√¥n ng·ªØ French: 11.149 \n",
    "  + T·ª´ xu·∫•t hi·ªán 1 l·∫ßn: 4.683\n",
    "  + Vocab gi·ªØ l·∫°i: 11.149 - 4.683 + 4 = 5893 t·ª´\n",
    "\n",
    "Ti·∫øng Anh (English)\n",
    "  + S·ªë t·ª´ xu·∫•t hi·ªán duy nh·∫•t (unique) ng√¥n ng·ªØ English: 9.793\n",
    "  + T·ª´ xu·∫•t hi·ªán 1 l·∫ßn: 3.904\n",
    "  + Vocab gi·ªØ l·∫°i: 9.793 - 3.904 + 4 = 6470 t·ª´\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e25cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29000/29000 [00:00<00:00, 42743.19it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29000/29000 [00:01<00:00, 25849.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vocab v√† dataset ƒë√£ l∆∞u xong.\n"
     ]
    }
   ],
   "source": [
    "from src.data import get_loader, save_vocab, save_dataset\n",
    "\n",
    "# Load DataLoader + Dataset\n",
    "train_loader, train_dataset = get_loader(\"data/train.en.gz\", \"data/train.fr.gz\", batch_size=32)\n",
    "\n",
    "# L∆∞u vocab v√† dataset\n",
    "save_vocab(train_dataset.src_vocab, \"data/vocab_en.pkl\")\n",
    "save_vocab(train_dataset.trg_vocab, \"data/vocab_fr.pkl\")\n",
    "save_dataset(train_dataset, \"data/train_dataset.pt\")\n",
    "\n",
    "print(\"‚úÖ Vocab v√† dataset ƒë√£ l∆∞u xong.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31e262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded EN vocab size: 5893\n",
      "Loaded FR vocab size: 6470\n",
      "Loaded dataset size: 29000\n"
     ]
    }
   ],
   "source": [
    "from src.data import load_vocab, load_dataset\n",
    "\n",
    "# Load l·∫°i vocab\n",
    "src_vocab = load_vocab(\"data/vocab_en.pkl\")\n",
    "trg_vocab = load_vocab(\"data/vocab_fr.pkl\")\n",
    "\n",
    "print(\"Loaded EN vocab size:\", len(src_vocab.stoi))\n",
    "print(\"Loaded FR vocab size:\", len(trg_vocab.stoi))\n",
    "\n",
    "# Load dataset ƒë√£ save\n",
    "train_dataset = load_dataset(\"data/train_dataset.pt\")\n",
    "print(\"Loaded dataset size:\", len(train_dataset))\n",
    "\n",
    "# train_dataset = load_dataset(\"data/train_dataset.pt\")\n",
    "# print(len(train_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88867936",
   "metadata": {},
   "source": [
    "Xem File vocab_en.pkl / vocab_fr.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4019a92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN vocab size: 5893\n",
      "FR vocab size: 6470\n",
      "EN sample: [('<pad>', 0), ('<sos>', 1), ('<eos>', 2), ('<unk>', 3), ('a', 4), ('.', 5), ('in', 6), ('the', 7), ('on', 8), ('man', 9)]\n",
      "FR sample: [('<pad>', 0), ('<sos>', 1), ('<eos>', 2), ('<unk>', 3), ('un', 4), ('.', 5), ('une', 6), ('de', 7), ('en', 8), (\"d'\", 9)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load vocab\n",
    "with open(\"data/vocab_en.pkl\", \"rb\") as f:\n",
    "    src_vocab = pickle.load(f)\n",
    "\n",
    "with open(\"data/vocab_fr.pkl\", \"rb\") as f:\n",
    "    trg_vocab = pickle.load(f)\n",
    "\n",
    "# Xem t·ªïng s·ªë t·ª´\n",
    "print(\"EN vocab size:\", len(src_vocab.stoi))\n",
    "print(\"FR vocab size:\", len(trg_vocab.stoi))\n",
    "\n",
    "# In 10 t·ª´ ƒë·∫ßu ti√™n trong vocab\n",
    "print(\"EN sample:\", list(src_vocab.stoi.items())[:10])\n",
    "print(\"FR sample:\", list(trg_vocab.stoi.items())[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c75542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "EN: <sos> two young , white males are outside near many bushes . <eos>\n",
      "FR: <sos> deux jeunes hommes blancs sont dehors pr√®s de buissons . <eos>\n",
      "---\n",
      "Sample 2:\n",
      "EN: <sos> several men in hard hats are operating a giant pulley system . <eos>\n",
      "FR: <sos> plusieurs hommes en casque font fonctionner un syst√®me de poulies g√©ant . <eos>\n",
      "---\n",
      "Sample 3:\n",
      "EN: <sos> a little girl climbing into a wooden playhouse . <eos>\n",
      "FR: <sos> une petite fille grimpe dans une maisonnette en bois . <eos>\n",
      "---\n",
      "Sample 4:\n",
      "EN: <sos> a man in a blue shirt is standing on a ladder cleaning a window . <eos>\n",
      "FR: <sos> un homme dans une chemise bleue se tient sur une √©chelle pour nettoyer une fen√™tre . <eos>\n",
      "---\n",
      "Sample 5:\n",
      "EN: <sos> two men are at the stove preparing food . <eos>\n",
      "FR: <sos> deux hommes aux fourneaux pr√©parent √† manger . <eos>\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = 5  # s·ªë c√¢u mu·ªën xem\n",
    "for i in range(NUM_SAMPLES):\n",
    "    src_idx, trg_idx = train_dataset[i]\n",
    "\n",
    "    # Chuy·ªÉn index -> t·ª´\n",
    "    src_words = [src_vocab.itos[idx.item()] for idx in src_idx if idx.item() not in [src_vocab.stoi[\"<pad>\"]]]\n",
    "    trg_words = [trg_vocab.itos[idx.item()] for idx in trg_idx if idx.item() not in [trg_vocab.stoi[\"<pad>\"]]]\n",
    "\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(\"EN:\", \" \".join(src_words))\n",
    "    print(\"FR:\", \" \".join(trg_words))\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459df4a6",
   "metadata": {},
   "source": [
    "2Ô∏è‚É£ Ki·ªÉm tra vocab v√† dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "907b53d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source indices: tensor([   1,   16,   24,   15,   25,  774,   17,   57,   80,  202, 1305,    5,\n",
      "           2])\n",
      "Target indices: tensor([   1,   21,   81,   32,  214,   28,   88,   70,    7, 1171,    5,    2])\n"
     ]
    }
   ],
   "source": [
    "src_example, trg_example = train_dataset[0]\n",
    "print(\"Source indices:\", src_example)\n",
    "print(\"Target indices:\", trg_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c0dc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sentence: <sos> two young , white males are outside near many bushes . <eos>\n",
      "Target sentence: <sos> deux jeunes hommes blancs sont dehors pr√®s de buissons . <eos>\n"
     ]
    }
   ],
   "source": [
    "src_words = [src_vocab.itos[idx.item()] for idx in src_example]\n",
    "trg_words = [trg_vocab.itos[idx.item()] for idx in trg_example]\n",
    "print(\"Source sentence:\", \" \".join(src_words))\n",
    "print(\"Target sentence:\", \" \".join(trg_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f9f863d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source indices: tensor([   1,   16,   24,   15,   25,  774,   17,   57,   80,  202, 1305,    5,\n",
      "           2])\n",
      "Target indices: tensor([   1,   21,   81,   32,  214,   28,   88,   70,    7, 1171,    5,    2])\n",
      "Source sentence: <sos> two young , white males are outside near many bushes . <eos>\n",
      "Target sentence: <sos> deux jeunes hommes blancs sont dehors pr√®s de buissons . <eos>\n"
     ]
    }
   ],
   "source": [
    "# L·∫•y m·ªôt sample ƒë·∫ßu ti√™n t·ª´ dataset\n",
    "src_example, trg_example = train_dataset[0]\n",
    "\n",
    "# In ra c√°c index (s·ªë) trong c√¢u\n",
    "print(\"Source indices:\", src_example)\n",
    "print(\"Target indices:\", trg_example)\n",
    "\n",
    "# Chuy·ªÉn c√°c index v·ªÅ t·ª´ ƒë·ªÉ ƒë·ªçc ƒë∆∞·ª£c\n",
    "src_words = [src_vocab.itos[idx.item()] for idx in src_example]\n",
    "trg_words = [trg_vocab.itos[idx.item()] for idx in trg_example]\n",
    "\n",
    "print(\"Source sentence:\", \" \".join(src_words))\n",
    "print(\"Target sentence:\", \" \".join(trg_words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee3dd3",
   "metadata": {},
   "source": [
    "3Ô∏è‚É£ Ki·ªÉm tra DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "150e780d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 23]) torch.Size([32, 25])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.data import load_dataset, MyCollate, load_vocab\n",
    "\n",
    "# Load dataset + vocab\n",
    "train_dataset = load_dataset(\"data/train_dataset.pt\")\n",
    "src_vocab = load_vocab(\"data/vocab_en.pkl\")\n",
    "trg_vocab = load_vocab(\"data/vocab_fr.pkl\")\n",
    "\n",
    "PAD_IDX = src_vocab.stoi[\"<pad>\"]\n",
    "\n",
    "# T·∫°o DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,\n",
    "                          collate_fn=MyCollate(PAD_IDX))\n",
    "\n",
    "# Xem shape batch ƒë·∫ßu ti√™n\n",
    "for src_batch, trg_batch in train_loader:\n",
    "    print(src_batch.shape, trg_batch.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b6816",
   "metadata": {},
   "source": [
    "src_batch.shape = [32, 23] ‚Üí batch size = 32, sequence length ngu·ªìn = 23 token.\n",
    "\n",
    "trg_batch.shape = [32, 25] ‚Üí batch size = 32, sequence length ƒë√≠ch = 25 token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a23c9",
   "metadata": {},
   "source": [
    "4Ô∏è‚É£ Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9492be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Loss: 4.3839\n",
      "Epoch [2/10] Loss: 3.4757\n",
      "Epoch [3/10] Loss: 3.0128\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SGU(1)\\official\\4-1\\NLP\\DoAn\\NMT_English_French\\src\\train_data.py:132\u001b[39m\n\u001b[32m    130\u001b[39m src, trg = src.to(DEVICE), trg.to(DEVICE)\n\u001b[32m    131\u001b[39m optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTEACHER_FORCING_RATIO\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# reshape for loss: (batch*seq_len, vocab_size)\u001b[39;00m\n\u001b[32m    135\u001b[39m output_dim = output.shape[-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SGU(1)\\official\\4-1\\NLP\\DoAn\\NMT_English_French\\src\\train_data.py:103\u001b[39m, in \u001b[36mSeq2Seq.forward\u001b[39m\u001b[34m(self, src, trg, teacher_forcing_ratio)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28minput\u001b[39m = trg[:,\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# <sos>\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, trg_len):\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     output, hidden, cell = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m     outputs[:,t,:] = output\n\u001b[32m    105\u001b[39m     teacher_force = torch.rand(\u001b[32m1\u001b[39m).item() < teacher_forcing_ratio\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SGU(1)\\official\\4-1\\NLP\\DoAn\\NMT_English_French\\src\\train_data.py:79\u001b[39m, in \u001b[36mDecoder.forward\u001b[39m\u001b[34m(self, x, hidden, cell)\u001b[39m\n\u001b[32m     77\u001b[39m embedded = \u001b[38;5;28mself\u001b[39m.embedding(x)\n\u001b[32m     78\u001b[39m outputs, (hidden, cell) = \u001b[38;5;28mself\u001b[39m.lstm(embedded, (hidden, cell))\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m predictions, hidden, cell\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%run src/train_data.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b0000",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for src, trg in train_loader:\n",
    "        src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "        output = model(src, trg, teacher_forcing_ratio=0)\n",
    "        top_words = output.argmax(-1)\n",
    "        print(\"Src:\", src[0])\n",
    "        print(\"Pred:\", top_words[0])\n",
    "        print(\"Trg:\", trg[0])\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeccd6f",
   "metadata": {},
   "source": [
    "5Ô∏è‚É£ Ki·ªÉm tra model sau training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22588e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"checkpoints/seq2seq_epoch10.pth\"))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    src_tensor = src_example.unsqueeze(0).to(DEVICE)\n",
    "    trg_tensor = trg_example.unsqueeze(0).to(DEVICE)\n",
    "    output = model(src_tensor, trg_tensor, teacher_forcing_ratio=0)\n",
    "    pred_indices = output.argmax(-1)[0].cpu().tolist()\n",
    "    pred_sentence = [trg_vocab.itos[idx] for idx in pred_indices]\n",
    "    print(\"Predicted sentence:\", \" \".join(pred_sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97549394",
   "metadata": {},
   "source": [
    "6Ô∏è‚É£ G·ª£i √Ω c·∫£i ti·∫øn\n",
    "\n",
    "1. Teacher forcing: hi·ªán t·∫°i l√† c·ªë ƒë·ªãnh 0.5. B·∫°n c√≥ th·ªÉ gi·∫£m d·∫ßn theo epoch\n",
    "\n",
    "2. Gradient clipping: tr√°nh exploding gradients v·ªõi LSTM:\n",
    "\n",
    "3. Validation set: n·∫øu c√≥ dataset validation, theo d√µi val_loss s·∫Ω t·ªët h∆°n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2356b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = max(0.5 * (0.9 ** epoch), 0.1)\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb4882",
   "metadata": {},
   "source": [
    "Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48560f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/seq2seq_epoch10.pth\"\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=DEVICE))\n",
    "model.eval()  # Chuy·ªÉn model sang ch·∫ø ƒë·ªô eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad5e2c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "GPU name: No GPU detected\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116a3692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)  # v√≠ d·ª•: '12.1'\n",
    "print(torch.cuda.is_available())  # True n·∫øu GPU OK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9919e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\~orch'.\n",
      "You can safely remove it manually.\n",
      "WARNING: Skipping torchvision as it is not installed.\n",
      "WARNING: Skipping torchaudio as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.9.0\n",
      "Uninstalling torch-2.9.0:\n",
      "  Successfully uninstalled torch-2.9.0\n"
     ]
    }
   ],
   "source": [
    "pip uninstall torch torchvision torchaudio -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd1de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
