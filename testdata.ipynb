{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a750d8",
   "metadata": {},
   "source": [
    "Kiểm tra DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c80e80ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29000/29000 [00:00<00:00, 41725.92it/s]\n",
      "100%|██████████| 29000/29000 [00:01<00:00, 28154.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 29000\n",
      "Vocab EN size: 5893\n",
      "Vocab FR size: 6470\n",
      "SRC shape: torch.Size([4, 17])\n",
      "TRG shape: torch.Size([4, 18])\n",
      "SRC example: tensor([   1,   16,   24,   15,   25,  774,   17,   57,   80,  202, 1305,    5,\n",
      "           2,    0,    0,    0,    0])\n",
      "TRG example: tensor([   1,   21,   81,   32,  214,   28,   88,   70,    7, 1171,    5,    2,\n",
      "           0,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.data import get_loader, load_vocab, load_dataset\n",
    "\n",
    "# Load DataLoader\n",
    "train_loader, train_dataset = get_loader(\"data/train.en.gz\", \"data/train.fr.gz\", batch_size=4, shuffle=False)\n",
    "\n",
    "print(f\"Dataset size: {len(train_dataset)}\")\n",
    "print(f\"Vocab EN size: {len(train_dataset.src_vocab.stoi)}\")\n",
    "print(f\"Vocab FR size: {len(train_dataset.trg_vocab.stoi)}\")\n",
    "\n",
    "# Kiểm tra batch đầu tiên\n",
    "for src, trg in train_loader:\n",
    "    print(\"SRC shape:\", src.shape)  # [batch_size, seq_len]\n",
    "    print(\"TRG shape:\", trg.shape)\n",
    "    print(\"SRC example:\", src[0])\n",
    "    print(\"TRG example:\", trg[0])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a83f7",
   "metadata": {},
   "source": [
    "Test việc lưu và load file vocab, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e25cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29000/29000 [00:00<00:00, 42743.19it/s]\n",
      "100%|██████████| 29000/29000 [00:01<00:00, 25849.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vocab và dataset đã lưu xong.\n"
     ]
    }
   ],
   "source": [
    "from src.data import get_loader, save_vocab, save_dataset\n",
    "\n",
    "# Load DataLoader + Dataset\n",
    "train_loader, train_dataset = get_loader(\"data/train.en.gz\", \"data/train.fr.gz\", batch_size=32)\n",
    "\n",
    "# Lưu vocab và dataset\n",
    "save_vocab(train_dataset.src_vocab, \"data/vocab_en.pkl\")\n",
    "save_vocab(train_dataset.trg_vocab, \"data/vocab_fr.pkl\")\n",
    "save_dataset(train_dataset, \"data/train_dataset.pt\")\n",
    "\n",
    "print(\"✅ Vocab và dataset đã lưu xong.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31e262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded EN vocab size: 5893\n",
      "Loaded FR vocab size: 6470\n",
      "Loaded dataset size: 29000\n"
     ]
    }
   ],
   "source": [
    "from src.data import load_vocab, load_dataset\n",
    "\n",
    "# Load lại vocab\n",
    "src_vocab = load_vocab(\"data/vocab_en.pkl\")\n",
    "trg_vocab = load_vocab(\"data/vocab_fr.pkl\")\n",
    "\n",
    "print(\"Loaded EN vocab size:\", len(src_vocab.stoi))\n",
    "print(\"Loaded FR vocab size:\", len(trg_vocab.stoi))\n",
    "\n",
    "# Load dataset đã save\n",
    "train_dataset = load_dataset(\"data/train_dataset.pt\")\n",
    "print(\"Loaded dataset size:\", len(train_dataset))\n",
    "\n",
    "# train_dataset = load_dataset(\"data/train_dataset.pt\")\n",
    "# print(len(train_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88867936",
   "metadata": {},
   "source": [
    "Xem File vocab_en.pkl / vocab_fr.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4019a92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN vocab size: 5893\n",
      "FR vocab size: 6470\n",
      "EN sample: [('<pad>', 0), ('<sos>', 1), ('<eos>', 2), ('<unk>', 3), ('a', 4), ('.', 5), ('in', 6), ('the', 7), ('on', 8), ('man', 9)]\n",
      "FR sample: [('<pad>', 0), ('<sos>', 1), ('<eos>', 2), ('<unk>', 3), ('un', 4), ('.', 5), ('une', 6), ('de', 7), ('en', 8), (\"d'\", 9)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load vocab\n",
    "with open(\"data/vocab_en.pkl\", \"rb\") as f:\n",
    "    src_vocab = pickle.load(f)\n",
    "\n",
    "with open(\"data/vocab_fr.pkl\", \"rb\") as f:\n",
    "    trg_vocab = pickle.load(f)\n",
    "\n",
    "# Xem tổng số từ\n",
    "print(\"EN vocab size:\", len(src_vocab.stoi))\n",
    "print(\"FR vocab size:\", len(trg_vocab.stoi))\n",
    "\n",
    "# In 10 từ đầu tiên trong vocab\n",
    "print(\"EN sample:\", list(src_vocab.stoi.items())[:10])\n",
    "print(\"FR sample:\", list(trg_vocab.stoi.items())[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c75542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "EN: <sos> two young , white males are outside near many bushes . <eos>\n",
      "FR: <sos> deux jeunes hommes blancs sont dehors près de buissons . <eos>\n",
      "---\n",
      "Sample 2:\n",
      "EN: <sos> several men in hard hats are operating a giant pulley system . <eos>\n",
      "FR: <sos> plusieurs hommes en casque font fonctionner un système de poulies géant . <eos>\n",
      "---\n",
      "Sample 3:\n",
      "EN: <sos> a little girl climbing into a wooden playhouse . <eos>\n",
      "FR: <sos> une petite fille grimpe dans une maisonnette en bois . <eos>\n",
      "---\n",
      "Sample 4:\n",
      "EN: <sos> a man in a blue shirt is standing on a ladder cleaning a window . <eos>\n",
      "FR: <sos> un homme dans une chemise bleue se tient sur une échelle pour nettoyer une fenêtre . <eos>\n",
      "---\n",
      "Sample 5:\n",
      "EN: <sos> two men are at the stove preparing food . <eos>\n",
      "FR: <sos> deux hommes aux fourneaux préparent à manger . <eos>\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = 5  # số câu muốn xem\n",
    "for i in range(NUM_SAMPLES):\n",
    "    src_idx, trg_idx = train_dataset[i]\n",
    "\n",
    "    # Chuyển index -> từ\n",
    "    src_words = [src_vocab.itos[idx.item()] for idx in src_idx if idx.item() not in [src_vocab.stoi[\"<pad>\"]]]\n",
    "    trg_words = [trg_vocab.itos[idx.item()] for idx in trg_idx if idx.item() not in [trg_vocab.stoi[\"<pad>\"]]]\n",
    "\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(\"EN:\", \" \".join(src_words))\n",
    "    print(\"FR:\", \" \".join(trg_words))\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459df4a6",
   "metadata": {},
   "source": [
    "2️⃣ Kiểm tra vocab và dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "907b53d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source indices: tensor([   1,   16,   24,   15,   25,  774,   17,   57,   80,  202, 1305,    5,\n",
      "           2])\n",
      "Target indices: tensor([   1,   21,   81,   32,  214,   28,   88,   70,    7, 1171,    5,    2])\n"
     ]
    }
   ],
   "source": [
    "src_example, trg_example = train_dataset[0]\n",
    "print(\"Source indices:\", src_example)\n",
    "print(\"Target indices:\", trg_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c0dc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sentence: <sos> two young , white males are outside near many bushes . <eos>\n",
      "Target sentence: <sos> deux jeunes hommes blancs sont dehors près de buissons . <eos>\n"
     ]
    }
   ],
   "source": [
    "src_words = [src_vocab.itos[idx.item()] for idx in src_example]\n",
    "trg_words = [trg_vocab.itos[idx.item()] for idx in trg_example]\n",
    "print(\"Source sentence:\", \" \".join(src_words))\n",
    "print(\"Target sentence:\", \" \".join(trg_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f9f863d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source indices: tensor([   1,   16,   24,   15,   25,  774,   17,   57,   80,  202, 1305,    5,\n",
      "           2])\n",
      "Target indices: tensor([   1,   21,   81,   32,  214,   28,   88,   70,    7, 1171,    5,    2])\n",
      "Source sentence: <sos> two young , white males are outside near many bushes . <eos>\n",
      "Target sentence: <sos> deux jeunes hommes blancs sont dehors près de buissons . <eos>\n"
     ]
    }
   ],
   "source": [
    "# Lấy một sample đầu tiên từ dataset\n",
    "src_example, trg_example = train_dataset[0]\n",
    "\n",
    "# In ra các index (số) trong câu\n",
    "print(\"Source indices:\", src_example)\n",
    "print(\"Target indices:\", trg_example)\n",
    "\n",
    "# Chuyển các index về từ để đọc được\n",
    "src_words = [src_vocab.itos[idx.item()] for idx in src_example]\n",
    "trg_words = [trg_vocab.itos[idx.item()] for idx in trg_example]\n",
    "\n",
    "print(\"Source sentence:\", \" \".join(src_words))\n",
    "print(\"Target sentence:\", \" \".join(trg_words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee3dd3",
   "metadata": {},
   "source": [
    "3️⃣ Kiểm tra DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "150e780d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 23]) torch.Size([32, 25])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.data import load_dataset, MyCollate, load_vocab\n",
    "\n",
    "# Load dataset + vocab\n",
    "train_dataset = load_dataset(\"data/train_dataset.pt\")\n",
    "src_vocab = load_vocab(\"data/vocab_en.pkl\")\n",
    "trg_vocab = load_vocab(\"data/vocab_fr.pkl\")\n",
    "\n",
    "PAD_IDX = src_vocab.stoi[\"<pad>\"]\n",
    "\n",
    "# Tạo DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,\n",
    "                          collate_fn=MyCollate(PAD_IDX))\n",
    "\n",
    "# Xem shape batch đầu tiên\n",
    "for src_batch, trg_batch in train_loader:\n",
    "    print(src_batch.shape, trg_batch.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b6816",
   "metadata": {},
   "source": [
    "src_batch.shape = [32, 23] → batch size = 32, sequence length nguồn = 23 token.\n",
    "\n",
    "trg_batch.shape = [32, 25] → batch size = 32, sequence length đích = 25 token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a23c9",
   "metadata": {},
   "source": [
    "4️⃣ Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d9492be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Loss: 4.3839\n",
      "Epoch [2/10] Loss: 3.4757\n",
      "Epoch [3/10] Loss: 3.0128\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SGU(1)\\official\\4-1\\NLP\\DoAn\\NMT_English_French\\src\\train_data.py:132\u001b[39m\n\u001b[32m    130\u001b[39m src, trg = src.to(DEVICE), trg.to(DEVICE)\n\u001b[32m    131\u001b[39m optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTEACHER_FORCING_RATIO\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# reshape for loss: (batch*seq_len, vocab_size)\u001b[39;00m\n\u001b[32m    135\u001b[39m output_dim = output.shape[-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SGU(1)\\official\\4-1\\NLP\\DoAn\\NMT_English_French\\src\\train_data.py:103\u001b[39m, in \u001b[36mSeq2Seq.forward\u001b[39m\u001b[34m(self, src, trg, teacher_forcing_ratio)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28minput\u001b[39m = trg[:,\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# <sos>\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, trg_len):\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     output, hidden, cell = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m     outputs[:,t,:] = output\n\u001b[32m    105\u001b[39m     teacher_force = torch.rand(\u001b[32m1\u001b[39m).item() < teacher_forcing_ratio\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SGU(1)\\official\\4-1\\NLP\\DoAn\\NMT_English_French\\src\\train_data.py:79\u001b[39m, in \u001b[36mDecoder.forward\u001b[39m\u001b[34m(self, x, hidden, cell)\u001b[39m\n\u001b[32m     77\u001b[39m embedded = \u001b[38;5;28mself\u001b[39m.embedding(x)\n\u001b[32m     78\u001b[39m outputs, (hidden, cell) = \u001b[38;5;28mself\u001b[39m.lstm(embedded, (hidden, cell))\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m predictions, hidden, cell\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%run src/train_data.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b0000",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for src, trg in train_loader:\n",
    "        src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "        output = model(src, trg, teacher_forcing_ratio=0)\n",
    "        top_words = output.argmax(-1)\n",
    "        print(\"Src:\", src[0])\n",
    "        print(\"Pred:\", top_words[0])\n",
    "        print(\"Trg:\", trg[0])\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeccd6f",
   "metadata": {},
   "source": [
    "5️⃣ Kiểm tra model sau training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22588e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"checkpoints/seq2seq_epoch10.pth\"))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    src_tensor = src_example.unsqueeze(0).to(DEVICE)\n",
    "    trg_tensor = trg_example.unsqueeze(0).to(DEVICE)\n",
    "    output = model(src_tensor, trg_tensor, teacher_forcing_ratio=0)\n",
    "    pred_indices = output.argmax(-1)[0].cpu().tolist()\n",
    "    pred_sentence = [trg_vocab.itos[idx] for idx in pred_indices]\n",
    "    print(\"Predicted sentence:\", \" \".join(pred_sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97549394",
   "metadata": {},
   "source": [
    "6️⃣ Gợi ý cải tiến\n",
    "\n",
    "1. Teacher forcing: hiện tại là cố định 0.5. Bạn có thể giảm dần theo epoch\n",
    "\n",
    "2. Gradient clipping: tránh exploding gradients với LSTM:\n",
    "\n",
    "3. Validation set: nếu có dataset validation, theo dõi val_loss sẽ tốt hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2356b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = max(0.5 * (0.9 ** epoch), 0.1)\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb4882",
   "metadata": {},
   "source": [
    "Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48560f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/seq2seq_epoch10.pth\"\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=DEVICE))\n",
    "model.eval()  # Chuyển model sang chế độ eval\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
