{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a750d8",
   "metadata": {},
   "source": [
    "1/ Ki·ªÉm tra DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c80e80ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29000/29000 [00:01<00:00, 28012.85it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29000/29000 [00:00<00:00, 33017.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 29000\n",
      "Vocab EN size: 5893\n",
      "Vocab FR size: 6470\n",
      "SRC shape: torch.Size([32, 24])\n",
      "TRG shape: torch.Size([32, 25])\n",
      "SRC example: tensor([   1,   16,   24,   15,   25,  774,   17,   57,   80,  202, 1305,    5,\n",
      "           2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "TRG example: tensor([   1,   21,   81,   32,  214,   28,   88,   70,    7, 1171,    5,    2,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.data import get_loader\n",
    "\n",
    "# Load DataLoader\n",
    "train_loader, train_dataset = get_loader(\"data/train.en.gz\", \"data/train.fr.gz\", batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Dataset size: {len(train_dataset)}\")\n",
    "print(f\"Vocab EN size: {len(train_dataset.src_vocab.stoi)}\")\n",
    "print(f\"Vocab FR size: {len(train_dataset.trg_vocab.stoi)}\")\n",
    "\n",
    "# Ki·ªÉm tra batch ƒë·∫ßu ti√™n\n",
    "for src, trg in train_loader:\n",
    "    print(\"SRC shape:\", src.shape)  # [batch_size, seq_len]\n",
    "    print(\"TRG shape:\", trg.shape)\n",
    "    print(\"SRC example:\", src[0])\n",
    "    print(\"TRG example:\", trg[0])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a83f7",
   "metadata": {},
   "source": [
    "Test vi·ªác l∆∞u v√† load file vocab, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e25cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29000/29000 [00:00<00:00, 85299.16it/s] \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29000/29000 [00:00<00:00, 57629.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vocab v√† dataset ƒë√£ l∆∞u xong.\n"
     ]
    }
   ],
   "source": [
    "from src.data import get_loader, save_vocab, save_dataset\n",
    "\n",
    "# Load DataLoader + Dataset\n",
    "train_loader, train_dataset = get_loader(\"data/train.en.gz\", \"data/train.fr.gz\", batch_size=32)\n",
    "\n",
    "# L∆∞u vocab v√† dataset\n",
    "save_vocab(train_dataset.src_vocab, \"data/vocab_en.pkl\")\n",
    "save_vocab(train_dataset.trg_vocab, \"data/vocab_fr.pkl\")\n",
    "save_dataset(train_dataset, \"data/train_dataset.pt\")\n",
    "\n",
    "print(\"‚úÖ Vocab v√† dataset ƒë√£ l∆∞u xong.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a31e262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded EN vocab size: 5893\n",
      "Loaded FR vocab size: 6470\n",
      "Loaded dataset size: 29000\n"
     ]
    }
   ],
   "source": [
    "from src.data import load_vocab, load_dataset\n",
    "\n",
    "# Load l·∫°i vocab\n",
    "src_vocab = load_vocab(\"data/vocab_en.pkl\")\n",
    "trg_vocab = load_vocab(\"data/vocab_fr.pkl\")\n",
    "\n",
    "print(\"Loaded EN vocab size:\", len(src_vocab.stoi))\n",
    "print(\"Loaded FR vocab size:\", len(trg_vocab.stoi))\n",
    "\n",
    "# Load dataset ƒë√£ save\n",
    "train_dataset = load_dataset(\"data/train_dataset.pt\")\n",
    "print(\"Loaded dataset size:\", len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88867936",
   "metadata": {},
   "source": [
    "2/ Xem File vocab_en.pkl / vocab_fr.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4019a92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN vocab size: 5893\n",
      "FR vocab size: 6470\n",
      "EN sample: [('<pad>', 0), ('<sos>', 1), ('<eos>', 2), ('<unk>', 3), ('a', 4), ('.', 5), ('in', 6), ('the', 7), ('on', 8), ('man', 9)]\n",
      "FR sample: [('<pad>', 0), ('<sos>', 1), ('<eos>', 2), ('<unk>', 3), ('un', 4), ('.', 5), ('une', 6), ('de', 7), ('en', 8), (\"d'\", 9)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load vocab\n",
    "with open(\"data/vocab_en.pkl\", \"rb\") as f:\n",
    "    src_vocab = pickle.load(f)\n",
    "\n",
    "with open(\"data/vocab_fr.pkl\", \"rb\") as f:\n",
    "    trg_vocab = pickle.load(f)\n",
    "\n",
    "# Xem t·ªïng s·ªë t·ª´\n",
    "print(\"EN vocab size:\", len(src_vocab.stoi))\n",
    "print(\"FR vocab size:\", len(trg_vocab.stoi))\n",
    "\n",
    "# In 10 t·ª´ ƒë·∫ßu ti√™n trong vocab\n",
    "print(\"EN sample:\", list(src_vocab.stoi.items())[:10])\n",
    "print(\"FR sample:\", list(trg_vocab.stoi.items())[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94c75542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "EN: <sos> two young , white males are outside near many bushes . <eos>\n",
      "FR: <sos> deux jeunes hommes blancs sont dehors pr√®s de buissons . <eos>\n",
      "---\n",
      "Sample 2:\n",
      "EN: <sos> several men in hard hats are operating a giant pulley system . <eos>\n",
      "FR: <sos> plusieurs hommes en casque font fonctionner un syst√®me de poulies g√©ant . <eos>\n",
      "---\n",
      "Sample 3:\n",
      "EN: <sos> a little girl climbing into a wooden playhouse . <eos>\n",
      "FR: <sos> une petite fille grimpe dans une maisonnette en bois . <eos>\n",
      "---\n",
      "Sample 4:\n",
      "EN: <sos> a man in a blue shirt is standing on a ladder cleaning a window . <eos>\n",
      "FR: <sos> un homme dans une chemise bleue se tient sur une √©chelle pour nettoyer une fen√™tre . <eos>\n",
      "---\n",
      "Sample 5:\n",
      "EN: <sos> two men are at the stove preparing food . <eos>\n",
      "FR: <sos> deux hommes aux fourneaux pr√©parent √† manger . <eos>\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = 5  # s·ªë c√¢u mu·ªën xem\n",
    "for i in range(NUM_SAMPLES):\n",
    "    src_idx, trg_idx = train_dataset[i]\n",
    "\n",
    "    # Chuy·ªÉn index -> t·ª´\n",
    "    src_words = [src_vocab.itos[idx.item()] for idx in src_idx if idx.item() not in [src_vocab.stoi[\"<pad>\"]]]\n",
    "    trg_words = [trg_vocab.itos[idx.item()] for idx in trg_idx if idx.item() not in [trg_vocab.stoi[\"<pad>\"]]]\n",
    "\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(\"EN:\", \" \".join(src_words))\n",
    "    print(\"FR:\", \" \".join(trg_words))\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459df4a6",
   "metadata": {},
   "source": [
    "2Ô∏è‚É£ Ki·ªÉm tra vocab v√† dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "907b53d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source indices: tensor([   1,   16,   24,   15,   25,  774,   17,   57,   80,  202, 1305,    5,\n",
      "           2])\n",
      "Target indices: tensor([   1,   21,   81,   32,  214,   28,   88,   70,    7, 1171,    5,    2])\n"
     ]
    }
   ],
   "source": [
    "src_example, trg_example = train_dataset[0]\n",
    "print(\"Source indices:\", src_example)\n",
    "print(\"Target indices:\", trg_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28c0dc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sentence: <sos> two young , white males are outside near many bushes . <eos>\n",
      "Target sentence: <sos> deux jeunes hommes blancs sont dehors pr√®s de buissons . <eos>\n"
     ]
    }
   ],
   "source": [
    "src_words = [src_vocab.itos[idx.item()] for idx in src_example]\n",
    "trg_words = [trg_vocab.itos[idx.item()] for idx in trg_example]\n",
    "print(\"Source sentence:\", \" \".join(src_words))\n",
    "print(\"Target sentence:\", \" \".join(trg_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f9f863d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source indices: tensor([   1,   16,   24,   15,   25,  774,   17,   57,   80,  202, 1305,    5,\n",
      "           2])\n",
      "Target indices: tensor([   1,   21,   81,   32,  214,   28,   88,   70,    7, 1171,    5,    2])\n",
      "Source sentence: <sos> two young , white males are outside near many bushes . <eos>\n",
      "Target sentence: <sos> deux jeunes hommes blancs sont dehors pr√®s de buissons . <eos>\n"
     ]
    }
   ],
   "source": [
    "# L·∫•y m·ªôt sample ƒë·∫ßu ti√™n t·ª´ dataset\n",
    "src_example, trg_example = train_dataset[0]\n",
    "\n",
    "# In ra c√°c index (s·ªë) trong c√¢u\n",
    "print(\"Source indices:\", src_example)\n",
    "print(\"Target indices:\", trg_example)\n",
    "\n",
    "# Chuy·ªÉn c√°c index v·ªÅ t·ª´ ƒë·ªÉ ƒë·ªçc ƒë∆∞·ª£c\n",
    "src_words = [src_vocab.itos[idx.item()] for idx in src_example]\n",
    "trg_words = [trg_vocab.itos[idx.item()] for idx in trg_example]\n",
    "\n",
    "print(\"Source sentence:\", \" \".join(src_words))\n",
    "print(\"Target sentence:\", \" \".join(trg_words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee3dd3",
   "metadata": {},
   "source": [
    "3Ô∏è‚É£ Ki·ªÉm tra DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "150e780d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 23]) torch.Size([32, 30])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.data import load_dataset, MyCollate, load_vocab\n",
    "\n",
    "# Load dataset + vocab\n",
    "train_dataset = load_dataset(\"data/train_dataset.pt\")\n",
    "src_vocab = load_vocab(\"data/vocab_en.pkl\")\n",
    "trg_vocab = load_vocab(\"data/vocab_fr.pkl\")\n",
    "\n",
    "PAD_IDX = src_vocab.stoi[\"<pad>\"]\n",
    "\n",
    "# T·∫°o DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,\n",
    "                          collate_fn=MyCollate(PAD_IDX))\n",
    "\n",
    "# Xem shape batch ƒë·∫ßu ti√™n\n",
    "for src_batch, trg_batch in train_loader:\n",
    "    print(src_batch.shape, trg_batch.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b6816",
   "metadata": {},
   "source": [
    "src_batch.shape = [32, 23] ‚Üí batch size = 32, sequence length ngu·ªìn = 23 token.\n",
    "\n",
    "trg_batch.shape = [32, 25] ‚Üí batch size = 32, sequence length ƒë√≠ch = 25 token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32743a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ T·ªïng s·ªë c√¢u: 29,000\n",
      "üìä ƒê·ªô d√†i c√¢u:\n",
      "   Trung b√¨nh: 13.11 t·ª´ / c√¢u\n",
      "   Ng·∫Øn nh·∫•t:  4 t·ª´\n",
      "   D√†i nh·∫•t:   41 t·ª´\n",
      "üß† T·ªïng s·ªë t·ª´ Ti·∫øng anh kh√°c nhau (unique words): 9,793\n",
      "\n",
      "üîù 20 t·ª´ ti·∫øng anh ph·ªï bi·∫øn nh·∫•t:\n",
      "a          ‚Üí 49165\n",
      ".          ‚Üí 27623\n",
      "in         ‚Üí 14886\n",
      "the        ‚Üí 10955\n",
      "on         ‚Üí 8035\n",
      "man        ‚Üí 7781\n",
      "is         ‚Üí 7525\n",
      "and        ‚Üí 7379\n",
      "of         ‚Üí 6871\n",
      "with       ‚Üí 6179\n",
      "woman      ‚Üí 3973\n",
      ",          ‚Üí 3963\n",
      "two        ‚Üí 3886\n",
      "are        ‚Üí 3717\n",
      "to         ‚Üí 3128\n",
      "people     ‚Üí 3122\n",
      "at         ‚Üí 2927\n",
      "an         ‚Üí 2861\n",
      "wearing    ‚Üí 2623\n",
      "shirt      ‚Üí 2324\n",
      "S·ªë t·ª´ ch·ªâ xu·∫•t hi·ªán 1 l·∫ßn: 3904\n",
      "T·ª∑ l·ªá t·ª´ hi·∫øm: 39.87%\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from collections import Counter\n",
    "import spacy\n",
    "\n",
    "# D√πng spaCy ƒë·ªÉ tokenize ti·∫øng Anh\n",
    "spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text.lower() for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "# ======= ƒê·ªçc file train.en ho·∫∑c train.en.gz =======\n",
    "file_path = \"data/train.en.gz\"\n",
    "\n",
    "if file_path.endswith(\".gz\"):\n",
    "    with gzip.open(file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read().strip().split(\"\\n\")\n",
    "else:\n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        lines = f.read().strip().split(\"\\n\")\n",
    "\n",
    "print(f\"‚úÖ T·ªïng s·ªë c√¢u: {len(lines):,}\")\n",
    "\n",
    "# ======= Tokenize to√†n b·ªô t·∫≠p =======\n",
    "tokenized_sentences = [tokenize_en(line) for line in lines]\n",
    "\n",
    "# ƒê·∫øm s·ªë t·ª´ trong t·ª´ng c√¢u\n",
    "sentence_lengths = [len(sent) for sent in tokenized_sentences]\n",
    "\n",
    "# T·ªïng h·ª£p th·ªëng k√™ ƒë·ªô d√†i c√¢u\n",
    "avg_len = sum(sentence_lengths) / len(sentence_lengths)\n",
    "max_len = max(sentence_lengths)\n",
    "min_len = min(sentence_lengths)\n",
    "\n",
    "print(f\"üìä ƒê·ªô d√†i c√¢u:\")\n",
    "print(f\"   Trung b√¨nh: {avg_len:.2f} t·ª´ / c√¢u\")\n",
    "print(f\"   Ng·∫Øn nh·∫•t:  {min_len} t·ª´\")\n",
    "print(f\"   D√†i nh·∫•t:   {max_len} t·ª´\")\n",
    "\n",
    "# ======= Th·ªëng k√™ t·ª´ v·ª±ng =======\n",
    "word_freq = Counter([word for sent in tokenized_sentences for word in sent])\n",
    "\n",
    "unique_words = len(word_freq)\n",
    "print(f\"üß† T·ªïng s·ªë t·ª´ Ti·∫øng anh kh√°c nhau (unique words): {unique_words:,}\")\n",
    "\n",
    "# Hi·ªÉn th·ªã 20 t·ª´ ph·ªï bi·∫øn nh·∫•t\n",
    "print(\"\\nüîù 20 t·ª´ ti·∫øng anh ph·ªï bi·∫øn nh·∫•t:\")\n",
    "for word, freq in word_freq.most_common(20):\n",
    "    print(f\"{word:10s} ‚Üí {freq}\")\n",
    "rare_words = [w for w, f in word_freq.items() if f == 1]\n",
    "print(f\"S·ªë t·ª´ ch·ªâ xu·∫•t hi·ªán 1 l·∫ßn: {len(rare_words)}\")\n",
    "print(f\"T·ª∑ l·ªá t·ª´ hi·∫øm: {len(rare_words)/len(word_freq)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84dea4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ T·ªïng s·ªë c√¢u: 29,000\n",
      "üìä ƒê·ªô d√†i c√¢u:\n",
      "   Trung b√¨nh: 14.28 t·ª´ / c√¢u\n",
      "   Ng·∫Øn nh·∫•t:  4 t·ª´\n",
      "   D√†i nh·∫•t:   54 t·ª´\n",
      "üß† T·ªïng s·ªë t·ª´ Ti·∫øng ph√°p kh√°c nhau (unique words): 11,149\n",
      "\n",
      "üîù 20 t·ª´ ti·∫øng ph√°p ph·ªï bi·∫øn nh·∫•t:\n",
      "un         ‚Üí 34942\n",
      ".          ‚Üí 27680\n",
      "une        ‚Üí 20624\n",
      "de         ‚Üí 14013\n",
      "en         ‚Üí 9866\n",
      "d'         ‚Üí 8139\n",
      "dans       ‚Üí 8059\n",
      "sur        ‚Üí 7957\n",
      "homme      ‚Üí 7887\n",
      "et         ‚Üí 7426\n",
      "des        ‚Üí 7406\n",
      "avec       ‚Üí 7177\n",
      "la         ‚Üí 5651\n",
      "√†          ‚Üí 5326\n",
      ",          ‚Üí 4800\n",
      "femme      ‚Üí 4454\n",
      "l'         ‚Üí 4284\n",
      "deux       ‚Üí 4068\n",
      "le         ‚Üí 3699\n",
      "est        ‚Üí 3257\n",
      "S·ªë t·ª´ ch·ªâ xu·∫•t hi·ªán 1 l·∫ßn: 4683\n",
      "T·ª∑ l·ªá t·ª´ hi·∫øm: 42.00%\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from collections import Counter\n",
    "import spacy\n",
    "\n",
    "# D√πng spaCy ƒë·ªÉ tokenize ti·∫øng Anh\n",
    "spacy_en = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text.lower() for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "# ======= ƒê·ªçc file train.en ho·∫∑c train.en.gz =======\n",
    "file_path = \"data/train.fr.gz\"\n",
    "\n",
    "if file_path.endswith(\".gz\"):\n",
    "    with gzip.open(file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read().strip().split(\"\\n\")\n",
    "else:\n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        lines = f.read().strip().split(\"\\n\")\n",
    "\n",
    "print(f\"‚úÖ T·ªïng s·ªë c√¢u: {len(lines):,}\")\n",
    "\n",
    "# ======= Tokenize to√†n b·ªô t·∫≠p =======\n",
    "tokenized_sentences = [tokenize_en(line) for line in lines]\n",
    "\n",
    "# ƒê·∫øm s·ªë t·ª´ trong t·ª´ng c√¢u\n",
    "sentence_lengths = [len(sent) for sent in tokenized_sentences]\n",
    "\n",
    "# T·ªïng h·ª£p th·ªëng k√™ ƒë·ªô d√†i c√¢u\n",
    "avg_len = sum(sentence_lengths) / len(sentence_lengths)\n",
    "max_len = max(sentence_lengths)\n",
    "min_len = min(sentence_lengths)\n",
    "\n",
    "print(f\"üìä ƒê·ªô d√†i c√¢u:\")\n",
    "print(f\"   Trung b√¨nh: {avg_len:.2f} t·ª´ / c√¢u\")\n",
    "print(f\"   Ng·∫Øn nh·∫•t:  {min_len} t·ª´\")\n",
    "print(f\"   D√†i nh·∫•t:   {max_len} t·ª´\")\n",
    "\n",
    "# ======= Th·ªëng k√™ t·ª´ v·ª±ng =======\n",
    "word_freq = Counter([word for sent in tokenized_sentences for word in sent])\n",
    "\n",
    "unique_words = len(word_freq)\n",
    "print(f\"üß† T·ªïng s·ªë t·ª´ Ti·∫øng ph√°p kh√°c nhau (unique words): {unique_words:,}\")\n",
    "\n",
    "# Hi·ªÉn th·ªã 20 t·ª´ ph·ªï bi·∫øn nh·∫•t\n",
    "print(\"\\nüîù 20 t·ª´ ti·∫øng ph√°p ph·ªï bi·∫øn nh·∫•t:\")\n",
    "for word, freq in word_freq.most_common(20):\n",
    "    print(f\"{word:10s} ‚Üí {freq}\")\n",
    "rare_words = [w for w, f in word_freq.items() if f == 1]\n",
    "print(f\"S·ªë t·ª´ ch·ªâ xu·∫•t hi·ªán 1 l·∫ßn: {len(rare_words)}\")\n",
    "print(f\"T·ª∑ l·ªá t·ª´ hi·∫øm: {len(rare_words)/len(word_freq)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a23c9",
   "metadata": {},
   "source": [
    "4Ô∏è‚É£ Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d9492be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run src/train_data.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e32b0000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for src, trg in train_loader:\n",
    "#         src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "#         output = model(src, trg, teacher_forcing_ratio=0)\n",
    "#         top_words = output.argmax(-1)\n",
    "#         # print(\"Src:\", src[0])\n",
    "#         print(\"Pred:\", top_words[0])\n",
    "#         print(\"Trg:\", trg[0])\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeccd6f",
   "metadata": {},
   "source": [
    "5Ô∏è‚É£ Ki·ªÉm tra model sau training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c22588e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"checkpoints/seq2seq_epoch10.pth\"))\n",
    "# model.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     src_tensor = src_example.unsqueeze(0).to(DEVICE)\n",
    "#     trg_tensor = trg_example.unsqueeze(0).to(DEVICE)\n",
    "#     output = model(src_tensor, trg_tensor, teacher_forcing_ratio=0)\n",
    "#     pred_indices = output.argmax(-1)[0].cpu().tolist()\n",
    "#     pred_sentence = [trg_vocab.itos[idx] for idx in pred_indices]\n",
    "#     print(\"Predicted sentence:\", \" \".join(pred_sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97549394",
   "metadata": {},
   "source": [
    "6Ô∏è‚É£ G·ª£i √Ω c·∫£i ti·∫øn\n",
    "\n",
    "1. Teacher forcing: hi·ªán t·∫°i l√† c·ªë ƒë·ªãnh 0.5. B·∫°n c√≥ th·ªÉ gi·∫£m d·∫ßn theo epoch\n",
    "\n",
    "2. Gradient clipping: tr√°nh exploding gradients v·ªõi LSTM:\n",
    "\n",
    "3. Validation set: n·∫øu c√≥ dataset validation, theo d√µi val_loss s·∫Ω t·ªët h∆°n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c2356b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher_forcing_ratio = max(0.5 * (0.9 ** epoch), 0.1)\n",
    "# torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb4882",
   "metadata": {},
   "source": [
    "Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a48560f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"checkpoints/seq2seq_epoch10.pth\"\n",
    "# model.load_state_dict(torch.load(checkpoint_path, map_location=DEVICE))\n",
    "# model.eval()  # Chuy·ªÉn model sang ch·∫ø ƒë·ªô eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5fca93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/300 | Loss: 0.0033\n",
      "Epoch 100/300 | Loss: 0.0014\n",
      "Epoch 150/300 | Loss: 0.0008\n",
      "Epoch 200/300 | Loss: 0.0005\n",
      "Epoch 250/300 | Loss: 0.0004\n",
      "Epoch 300/300 | Loss: 0.0003\n",
      "\n",
      "üß© Translation Test:\n",
      "i am a student ‚Üí je suis un √©tudiant\n",
      "he is a teacher ‚Üí il est un enseignant\n",
      "she is happy ‚Üí elle est heureuse\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üß† Mini Seq2Seq Translation Example\n",
    "# ============================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import tensor\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1Ô∏è‚É£ Data\n",
    "# -----------------------------------------------------\n",
    "train_en = [\n",
    "    \"i am a student\",\n",
    "    \"he is a teacher\",\n",
    "    \"she is happy\"\n",
    "]\n",
    "\n",
    "train_fr = [\n",
    "    \"je suis un √©tudiant\",\n",
    "    \"il est un enseignant\",\n",
    "    \"elle est heureuse\"\n",
    "]\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2Ô∏è‚É£ Vocabulary\n",
    "# -----------------------------------------------------\n",
    "vocab_en = {\n",
    "    \"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3,\n",
    "    \"i\": 4, \"am\": 5, \"a\": 6, \"student\": 7,\n",
    "    \"he\": 8, \"is\": 9, \"teacher\": 10,\n",
    "    \"she\": 11, \"happy\": 12\n",
    "}\n",
    "\n",
    "vocab_fr = {\n",
    "    \"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3,\n",
    "    \"je\": 4, \"suis\": 5, \"un\": 6, \"√©tudiant\": 7,\n",
    "    \"il\": 8, \"est\": 9, \"enseignant\": 10,\n",
    "    \"elle\": 11, \"heureuse\": 12\n",
    "}\n",
    "\n",
    "def sentence_to_tensor(sentence, vocab):\n",
    "    tokens = sentence.split()\n",
    "    ids = [vocab[\"<sos>\"]] + [vocab.get(tok, vocab[\"<unk>\"]) for tok in tokens] + [vocab[\"<eos>\"]]\n",
    "    return tensor(ids)\n",
    "\n",
    "pairs = [(sentence_to_tensor(e, vocab_en), sentence_to_tensor(f, vocab_fr))\n",
    "         for e, f in zip(train_en, train_fr)]\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3Ô∏è‚É£ Model\n",
    "# -----------------------------------------------------\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size)\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        pred = self.fc(output)\n",
    "        return pred, hidden\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4Ô∏è‚É£ Instantiate\n",
    "# -----------------------------------------------------\n",
    "embed_size, hidden_size = 32, 64\n",
    "encoder = Encoder(len(vocab_en), embed_size, hidden_size)\n",
    "decoder = Decoder(len(vocab_fr), embed_size, hidden_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab_fr[\"<pad>\"])\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.01)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5Ô∏è‚É£ Training Loop\n",
    "# -----------------------------------------------------\n",
    "EPOCHS = 300\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for src, trg in pairs:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        hidden = encoder(src.unsqueeze(1))  # (seq_len, batch=1)\n",
    "        decoder_input = trg[:-1].unsqueeze(1)\n",
    "        decoder_target = trg[1:]\n",
    "\n",
    "        output, _ = decoder(decoder_input, hidden)\n",
    "        output = output.squeeze(1)\n",
    "        loss = criterion(output, decoder_target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {total_loss:.4f}\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6Ô∏è‚É£ Test (greedy decoding)\n",
    "# -----------------------------------------------------\n",
    "def translate(sentence):\n",
    "    with torch.no_grad():\n",
    "        src = sentence_to_tensor(sentence, vocab_en)\n",
    "        hidden = encoder(src.unsqueeze(1))\n",
    "\n",
    "        input_token = tensor([[vocab_fr[\"<sos>\"]]])\n",
    "        result = []\n",
    "\n",
    "        for _ in range(10):\n",
    "            output, hidden = decoder(input_token, hidden)\n",
    "            token = output.argmax(2)[0, 0].item()\n",
    "            if token == vocab_fr[\"<eos>\"]:\n",
    "                break\n",
    "            result.append(token)\n",
    "            input_token = tensor([[token]])\n",
    "\n",
    "        inv_vocab_fr = {v: k for k, v in vocab_fr.items()}\n",
    "        translated = \" \".join(inv_vocab_fr[t] for t in result)\n",
    "        return translated\n",
    "\n",
    "print(\"\\nüß© Translation Test:\")\n",
    "for s in train_en:\n",
    "    print(f\"{s} ‚Üí {translate(s)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e57c0a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29000/29000 [00:00<00:00, 82713.54it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29000/29000 [00:00<00:00, 60662.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset ƒë√£ load xong!\n",
      "T·ªïng s·ªë c√¢u: 29000\n",
      "Vocab EN: 5893 t·ª´\n",
      "Vocab FR: 6470 t·ª´\n",
      "\n",
      "üíæ ƒê√£ l∆∞u vocab v√† dataset th√†nh c√¥ng!\n",
      "\n",
      "SRC shape: torch.Size([4, 17])\n",
      "TRG shape: torch.Size([4, 18])\n",
      "\n",
      "SRC example (index): tensor([   1,   16,   24,   15,   25,  774,   17,   57,   80,  202, 1305,    5,\n",
      "           2,    0,    0,    0,    0])\n",
      "TRG example (index): tensor([   1,   21,   81,   32,  214,   28,   88,   70,    7, 1171,    5,    2,\n",
      "           0,    0,    0,    0,    0,    0])\n",
      "\n",
      "üß© C√¢u m·∫´u sau khi gi·∫£i m√£:\n",
      "EN: <sos> two young , white males are outside near many bushes . <eos>\n",
      "FR: <sos> deux jeunes hommes blancs sont dehors pr√®s de buissons . <eos>\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üß† DEMO: Ki·ªÉm tra Dataset v√† Vocab\n",
    "# ============================================\n",
    "\n",
    "import torch\n",
    "from src.data import get_loader, save_vocab, load_vocab, save_dataset, load_dataset\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1Ô∏è‚É£ Load DataLoader (ƒë·ªçc t·ª´ file train.en.gz, train.fr.gz)\n",
    "# --------------------------------------------------\n",
    "train_loader, train_dataset = get_loader(\n",
    "    src_path=\"data/train.en.gz\",\n",
    "    trg_path=\"data/train.fr.gz\",\n",
    "    batch_size=4,   # ch·ªçn nh·ªè ƒë·ªÉ xem d·ªÖ\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Dataset ƒë√£ load xong!\")\n",
    "print(f\"T·ªïng s·ªë c√¢u: {len(train_dataset)}\")\n",
    "print(f\"Vocab EN: {len(train_dataset.src_vocab.stoi)} t·ª´\")\n",
    "print(f\"Vocab FR: {len(train_dataset.trg_vocab.stoi)} t·ª´\\n\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2Ô∏è‚É£ L∆∞u vocab v√† dataset ƒë·ªÉ d√πng l·∫°i sau n√†y\n",
    "# --------------------------------------------------\n",
    "save_vocab(train_dataset.src_vocab, \"data/vocab_en.pkl\")\n",
    "save_vocab(train_dataset.trg_vocab, \"data/vocab_fr.pkl\")\n",
    "save_dataset(train_dataset, \"data/train_dataset.pt\")\n",
    "\n",
    "print(\"üíæ ƒê√£ l∆∞u vocab v√† dataset th√†nh c√¥ng!\\n\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3Ô∏è‚É£ Ki·ªÉm tra batch ƒë·∫ßu ti√™n\n",
    "# --------------------------------------------------\n",
    "for src, trg in train_loader:\n",
    "    print(\"SRC shape:\", src.shape)\n",
    "    print(\"TRG shape:\", trg.shape)\n",
    "    print(\"\\nSRC example (index):\", src[0])\n",
    "    print(\"TRG example (index):\", trg[0])\n",
    "    break\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4Ô∏è‚É£ Gi·∫£i m√£ l·∫°i (hi·ªÉn th·ªã c√¢u g·ªëc)\n",
    "# --------------------------------------------------\n",
    "itos_en = train_dataset.src_vocab.itos\n",
    "itos_fr = train_dataset.trg_vocab.itos\n",
    "\n",
    "def decode(tensor, vocab_itos):\n",
    "    tokens = [vocab_itos[idx.item()] for idx in tensor if idx.item() not in [0]]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "print(\"\\nüß© C√¢u m·∫´u sau khi gi·∫£i m√£:\")\n",
    "print(\"EN:\", decode(src[0], itos_en))\n",
    "print(\"FR:\", decode(trg[0], itos_fr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a98ab745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1] Loss: 4.1831\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load dataset + vocab\n",
    "Kh·ªüi t·∫°o Encoder‚ÄìDecoder LSTM\n",
    "Teacher Forcing\n",
    "CrossEntropyLoss (ignore <pad>)\n",
    "L∆∞u checkpoint .pth\n",
    "In loss + plot bi·ªÉu ƒë·ªì\n",
    "\n",
    "‚úÖ ƒêi·ªÉm n·ªïi b·∫≠t:\n",
    "Dataset & vocab ƒë∆∞·ª£c load t·ª´ .pt v√† .pkl ‚Üí ti·∫øt ki·ªám th·ªùi gian tokenization v√† build vocab\n",
    "Encoder‚ÄìDecoder LSTM c∆° b·∫£n, kh√¥ng d√πng attention\n",
    "Teacher Forcing t√πy ch·ªânh v·ªõi TEACHER_FORCING_RATIO\n",
    "CrossEntropyLoss ignore <pad>\n",
    "Checkpoint .pth l∆∞u m·ªói epoch\n",
    "Plot loss sau khi train\n",
    "\"\"\"\n",
    "\n",
    "# src/train.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from src.data import load_dataset, load_vocab, MyCollate, TranslationDataset  # import from package src.data\n",
    "\n",
    "# =============================\n",
    "# 1. Hyperparameters\n",
    "# =============================\n",
    "BATCH_SIZE = 32\n",
    "EMBED_SIZE = 256\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_LAYERS = 1\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 1\n",
    "TEACHER_FORCING_RATIO = 0.5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# =============================\n",
    "# 2. Load dataset + vocab\n",
    "# =============================\n",
    "train_dataset = load_dataset(\"data/train_dataset.pt\")\n",
    "src_vocab = load_vocab(\"data/vocab_en.pkl\")\n",
    "trg_vocab = load_vocab(\"data/vocab_fr.pkl\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          collate_fn=MyCollate(train_dataset.pad_idx))\n",
    "\n",
    "PAD_IDX = src_vocab.stoi[\"<pad>\"]\n",
    "\n",
    "# =============================\n",
    "# 3. Encoder\n",
    "# =============================\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embed_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embed_size, padding_idx=PAD_IDX)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.embedding(x)\n",
    "        packed = pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, (hidden, cell) = self.lstm(packed)\n",
    "        output, _ = pad_packed_sequence(packed_out, batch_first=True, padding_value=PAD_IDX)\n",
    "        return hidden, cell\n",
    "\n",
    "# =============================\n",
    "# 4. Decoder\n",
    "# =============================\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embed_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, embed_size, padding_idx=PAD_IDX)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_dim)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = x.unsqueeze(1)  # (batch, 1)\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        predictions = self.fc(outputs.squeeze(1))\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "# =============================\n",
    "# 5. Seq2Seq\n",
    "# =============================\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = len(trg_vocab.stoi)\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "\n",
    "         # =============================\n",
    "        # T√≠nh ƒë·ªô d√†i th·ª±c t·∫ø ƒë·ªÉ pack\n",
    "        # =============================\n",
    "        lengths = (src != PAD_IDX).sum(dim=1)\n",
    "        hidden, cell = self.encoder(src, lengths)\n",
    "        input = trg[:,0]  # <sos>\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[:,t,:] = output\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:,t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "\n",
    "# =============================\n",
    "# 6. Initialize model + optimizer + loss\n",
    "# =============================\n",
    "encoder = Encoder(len(src_vocab.stoi), EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS).to(DEVICE)\n",
    "decoder = Decoder(len(trg_vocab.stoi), EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS).to(DEVICE)\n",
    "model = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "# =============================\n",
    "# 7. Training loop\n",
    "# =============================\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for src, trg in train_loader:\n",
    "        src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio=TEACHER_FORCING_RATIO)\n",
    "\n",
    "        # reshape for loss: (batch*seq_len, vocab_size)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:,1:,:].reshape(-1, output_dim)\n",
    "        trg = trg[:,1:].reshape(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    loss_list.append(avg_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # save checkpoint\n",
    "    torch.save(model.state_dict(), f\"checkpoints/seq2seq_epoch{epoch+1}.pth\")\n",
    "\n",
    "# =============================\n",
    "# 8. Plot loss\n",
    "# =============================\n",
    "plt.plot(range(1, NUM_EPOCHS+1), loss_list, marker='o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# =============================\n",
    "# 9. Translation (Inference)\n",
    "# =============================\n",
    "\n",
    "# üëâ Thay v√¨ torchtext, ta d√πng NLTK ƒë·ªÉ t√≠nh BLEU\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def translate_sentence(sentence, src_vocab, trg_vocab, model, device, max_len=50):\n",
    "    model.eval()\n",
    "    # d√πng spaCy tokenizer gi·ªëng l√∫c train\n",
    "    tokens = [\"<sos>\"] + [tok.text.lower() for tok in spacy_en.tokenizer(sentence)] + [\"<eos>\"]\n",
    "    src_indexes = [src_vocab.stoi.get(tok, src_vocab.stoi[\"<unk>\"]) for tok in tokens]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "    lengths = (src_tensor != src_vocab.stoi[\"<pad>\"]).sum(dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(src_tensor, lengths)\n",
    "\n",
    "    trg_indexes = [trg_vocab.stoi[\"<sos>\"]]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
    "            pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        if pred_token == trg_vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    trg_tokens = [trg_vocab.itos[i] for i in trg_indexes]\n",
    "    return \" \".join(trg_tokens[1:-1])\n",
    "\n",
    "\n",
    "# =============================\n",
    "# 10. Evaluation ‚Äì BLEU Score (NLTK)\n",
    "# =============================\n",
    "\n",
    "def calculate_bleu_score(dataloader, model, src_vocab, trg_vocab, device, n_samples=50):\n",
    "    \"\"\"\n",
    "    T√≠nh BLEU score trung b√¨nh tr√™n n c√¢u test ng·∫´u nhi√™n\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    count = 0\n",
    "\n",
    "    smoothie = SmoothingFunction().method4  # l√†m m∆∞·ª£t BLEU ƒë·ªÉ tr√°nh 0 khi c√¢u ng·∫Øn\n",
    "\n",
    "    for src, trg in dataloader:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        for i in range(src.shape[0]):\n",
    "            src_tokens = [src_vocab.itos[idx] for idx in src[i].cpu().numpy()\n",
    "                          if idx not in [src_vocab.stoi[\"<pad>\"], src_vocab.stoi[\"<sos>\"], src_vocab.stoi[\"<eos>\"]]]\n",
    "            trg_tokens = [trg_vocab.itos[idx] for idx in trg[i].cpu().numpy()\n",
    "                          if idx not in [trg_vocab.stoi[\"<pad>\"], trg_vocab.stoi[\"<sos>\"], trg_vocab.stoi[\"<eos>\"]]]\n",
    "            src_sentence = \" \".join(src_tokens)\n",
    "            pred = translate_sentence(src_sentence, src_vocab, trg_vocab, model, device)\n",
    "            preds.append(pred.split())\n",
    "            targets.append([trg_tokens])\n",
    "            count += 1\n",
    "            if count >= n_samples:\n",
    "                break\n",
    "        if count >= n_samples:\n",
    "            break\n",
    "\n",
    "    # T√≠nh BLEU trung b√¨nh\n",
    "    scores = [\n",
    "        sentence_bleu(ref, pred, smoothing_function=smoothie)\n",
    "        for pred, ref in zip(preds, targets)\n",
    "    ]\n",
    "    bleu = sum(scores) / len(scores)\n",
    "    print(f\"BLEU score (tr√™n {n_samples} m·∫´u): {bleu*100:.2f}\")\n",
    "    return bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "523c37b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy_en' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m example \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTwo young, White males are outside near many bushes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m translated \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müîπ English: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müî∏ French: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtranslated\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[26], line 176\u001b[0m, in \u001b[0;36mtranslate_sentence\u001b[1;34m(sentence, src_vocab, trg_vocab, model, device, max_len)\u001b[0m\n\u001b[0;32m    174\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# d√πng spaCy tokenizer gi·ªëng l√∫c train\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<sos>\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m [tok\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m \u001b[43mspacy_en\u001b[49m\u001b[38;5;241m.\u001b[39mtokenizer(sentence)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<eos>\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    177\u001b[0m src_indexes \u001b[38;5;241m=\u001b[39m [src_vocab\u001b[38;5;241m.\u001b[39mstoi\u001b[38;5;241m.\u001b[39mget(tok, src_vocab\u001b[38;5;241m.\u001b[39mstoi[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<unk>\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m tokens]\n\u001b[0;32m    178\u001b[0m src_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(src_indexes)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spacy_en' is not defined"
     ]
    }
   ],
   "source": [
    "example = \"Two young, White males are outside near many bushes.\"\n",
    "translated = translate_sentence(example, src_vocab, trg_vocab, model, DEVICE)\n",
    "print(f\"\\nüîπ English: {example}\")\n",
    "print(f\"üî∏ French: {translated}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f927dfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.6.0\n",
      "Uninstalling torch-2.6.0:\n",
      "  Successfully uninstalled torch-2.6.0\n",
      "Found existing installation: torchtext 0.18.0\n",
      "Uninstalling torchtext-0.18.0:\n",
      "  Successfully uninstalled torchtext-0.18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\doqua\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\~orch'.\n",
      "You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch==2.2.2\n",
      "  Downloading torch-2.2.2-cp312-cp312-win_amd64.whl.metadata (26 kB)\n",
      "Collecting torchtext==0.17.2\n",
      "  Downloading torchtext-0.17.2-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.2) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.2) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.2) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.2) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.2) (2025.3.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchtext==0.17.2) (4.67.1)\n",
      "Requirement already satisfied: requests in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchtext==0.17.2) (2.32.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchtext==0.17.2) (2.3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch==2.2.2) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->torchtext==0.17.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->torchtext==0.17.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->torchtext==0.17.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->torchtext==0.17.2) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\doqua\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm->torchtext==0.17.2) (0.4.6)\n",
      "Downloading torch-2.2.2-cp312-cp312-win_amd64.whl (198.5 MB)\n",
      "   ---------------------------------------- 0.0/198.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/198.5 MB 5.6 MB/s eta 0:00:36\n",
      "    --------------------------------------- 3.4/198.5 MB 10.1 MB/s eta 0:00:20\n",
      "    --------------------------------------- 4.5/198.5 MB 8.1 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 6.6/198.5 MB 8.6 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 8.4/198.5 MB 8.7 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 9.7/198.5 MB 8.2 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 11.8/198.5 MB 8.4 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 13.9/198.5 MB 8.6 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 16.0/198.5 MB 8.7 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 17.8/198.5 MB 8.8 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 19.9/198.5 MB 8.8 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 22.0/198.5 MB 8.9 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 24.1/198.5 MB 8.9 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 26.2/198.5 MB 9.0 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 28.0/198.5 MB 9.0 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 30.1/198.5 MB 9.0 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 32.0/198.5 MB 9.0 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 33.6/198.5 MB 8.9 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 35.4/198.5 MB 8.9 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 37.2/198.5 MB 8.9 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 39.1/198.5 MB 8.9 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 40.9/198.5 MB 8.9 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 42.7/198.5 MB 8.9 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 44.8/198.5 MB 8.9 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 46.9/198.5 MB 8.9 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 48.8/198.5 MB 8.9 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 51.1/198.5 MB 9.0 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 53.2/198.5 MB 9.0 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 55.3/198.5 MB 9.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 57.4/198.5 MB 9.1 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 59.8/198.5 MB 9.1 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 62.1/198.5 MB 9.2 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 64.2/198.5 MB 9.2 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 66.6/198.5 MB 9.3 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 68.9/198.5 MB 9.3 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 71.3/198.5 MB 9.4 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 73.7/198.5 MB 9.4 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 76.0/198.5 MB 9.5 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 78.4/198.5 MB 9.5 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 80.7/198.5 MB 9.5 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 83.4/198.5 MB 9.6 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 85.7/198.5 MB 9.6 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 87.8/198.5 MB 9.6 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 90.2/198.5 MB 9.7 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 92.5/198.5 MB 9.7 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 94.9/198.5 MB 9.8 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 97.3/198.5 MB 9.8 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 99.9/198.5 MB 9.8 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 102.2/198.5 MB 9.9 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 104.9/198.5 MB 9.9 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 107.2/198.5 MB 9.9 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 109.6/198.5 MB 10.0 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 111.7/198.5 MB 9.9 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 113.8/198.5 MB 10.0 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 115.9/198.5 MB 10.0 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 118.2/198.5 MB 10.0 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 120.6/198.5 MB 10.0 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 122.7/198.5 MB 10.0 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 125.0/198.5 MB 10.0 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 126.9/198.5 MB 10.0 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 129.0/198.5 MB 10.0 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 130.3/198.5 MB 9.9 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 131.6/198.5 MB 9.8 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 132.6/198.5 MB 9.8 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 133.4/198.5 MB 9.7 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 134.5/198.5 MB 9.6 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 135.5/198.5 MB 9.6 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 136.6/198.5 MB 9.5 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 137.9/198.5 MB 9.4 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 138.9/198.5 MB 9.4 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 140.2/198.5 MB 9.3 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 141.3/198.5 MB 9.3 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 142.6/198.5 MB 9.2 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 143.9/198.5 MB 9.2 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 145.2/198.5 MB 9.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 146.5/198.5 MB 9.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 148.1/198.5 MB 9.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 149.7/198.5 MB 9.0 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 151.0/198.5 MB 9.0 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 152.6/198.5 MB 9.0 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 154.1/198.5 MB 9.0 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 155.7/198.5 MB 8.9 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 157.3/198.5 MB 8.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 158.9/198.5 MB 8.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 160.4/198.5 MB 8.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 162.3/198.5 MB 8.9 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 163.8/198.5 MB 8.9 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 165.7/198.5 MB 8.9 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 167.5/198.5 MB 8.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 169.3/198.5 MB 8.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 171.2/198.5 MB 8.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 173.0/198.5 MB 8.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 174.9/198.5 MB 8.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 176.9/198.5 MB 8.9 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 179.0/198.5 MB 8.9 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 180.9/198.5 MB 8.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 183.0/198.5 MB 8.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 185.1/198.5 MB 8.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 187.2/198.5 MB 8.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 189.3/198.5 MB 8.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 191.4/198.5 MB 8.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 193.5/198.5 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  195.6/198.5 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.9/198.5 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.4/198.5 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 198.5/198.5 MB 8.9 MB/s eta 0:00:00\n",
      "Downloading torchtext-0.17.2-cp312-cp312-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.9/1.9 MB 9.0 MB/s eta 0:00:00\n",
      "Installing collected packages: torch, torchtext\n",
      "\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   ---------------------------------------- 0/2 [torch]\n",
      "   -------------------- ------------------- 1/2 [torchtext]\n",
      "   -------------------- ------------------- 1/2 [torchtext]\n",
      "   -------------------- ------------------- 1/2 [torchtext]\n",
      "   -------------------- ------------------- 1/2 [torchtext]\n",
      "   -------------------- ------------------- 1/2 [torchtext]\n",
      "   -------------------- ------------------- 1/2 [torchtext]\n",
      "   -------------------- ------------------- 1/2 [torchtext]\n",
      "   -------------------- ------------------- 1/2 [torchtext]\n",
      "   -------------------- ------------------- 1/2 [torchtext]\n",
      "   -------------------- ------------------- 1/2 [torchtext]\n",
      "   ---------------------------------------- 2/2 [torchtext]\n",
      "\n",
      "Successfully installed torch-2.2.2 torchtext-0.17.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\doqua\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchtext -y\n",
    "!pip install torch==2.2.2 torchtext==0.17.2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
