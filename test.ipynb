{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb33ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29000/29000 [00:00<00:00, 72137.60it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29000/29000 [00:00<00:00, 49780.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC shape: torch.Size([4, 17])\n",
      "TRG shape: torch.Size([4, 18])\n",
      "Example src idx: tensor([ 1,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.dataset import get_loader\n",
    "\n",
    "train_loader, train_dataset = get_loader(\n",
    "    \"data/train.en.gz\", \"data/train.fr.gz\", batch_size=4, shuffle=False\n",
    ")\n",
    "\n",
    "for src, trg in train_loader:\n",
    "    print(\"SRC shape:\", src.shape)\n",
    "    print(\"TRG shape:\", trg.shape)\n",
    "    print(\"Example src idx:\", src[0][:10])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6243825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29000/29000 [00:00<00:00, 31956.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29000/29000 [00:01<00:00, 22961.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC shape: torch.Size([4, 20])\n",
      "TRG shape: torch.Size([4, 22])\n",
      "âœ… Loading cached English dataset: cache\\train_en_gz.pkl\n",
      "âœ… Loading cached French dataset: cache\\train_fr_gz.pkl\n",
      "SRC shape: torch.Size([4, 22])\n",
      "TRG shape: torch.Size([4, 22])\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from src import dataset\n",
    "importlib.reload(dataset)\n",
    "from src.dataset import get_loader, get_loader_cached\n",
    "\n",
    "# (1) Load tá»« file nÃ©n vÃ  táº¡o DataLoader má»›i\n",
    "train_loader, train_dataset = get_loader(\"data/train.en.gz\", \"data/train.fr.gz\", batch_size=4)\n",
    "\n",
    "for src, trg in train_loader:\n",
    "    print(\"SRC shape:\", src.shape)\n",
    "    print(\"TRG shape:\", trg.shape)\n",
    "    break\n",
    "\n",
    "# (2) Load láº¡i báº±ng cache (tá»± Ä‘á»™ng load tá»« file .pkl náº¿u cÃ³)\n",
    "train_loader, train_dataset = get_loader_cached(\"data/train.en.gz\", \"data/train.fr.gz\", batch_size=4)\n",
    "\n",
    "for src, trg in train_loader:\n",
    "    print(\"SRC shape:\", src.shape)\n",
    "    print(\"TRG shape:\", trg.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df8eb773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29000/29000 [00:01<00:00, 26296.93it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29000/29000 [00:00<00:00, 31886.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC shape: torch.Size([4, 15])\n",
      "TRG shape: torch.Size([4, 17])\n",
      "ðŸš€ Building English dataset from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29000/29000 [00:00<00:00, 68712.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Saved English cache: cache\\train_en_gz.pt\n",
      "ðŸš€ Building French dataset from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29000/29000 [00:00<00:00, 46465.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Saved French cache: cache\\train_fr_gz.pt\n",
      "SRC shape: torch.Size([4, 37])\n",
      "TRG shape: torch.Size([4, 37])\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from src import dataset\n",
    "importlib.reload(dataset)\n",
    "from src.dataset import get_loader, get_loader_cached\n",
    "\n",
    "# (1) Load tá»« file nÃ©n vÃ  táº¡o DataLoader má»›i\n",
    "train_loader, train_dataset = get_loader(\"data/train.en.gz\", \"data/train.fr.gz\", batch_size=4)\n",
    "\n",
    "for src, trg in train_loader:\n",
    "    print(\"SRC shape:\", src.shape)\n",
    "    print(\"TRG shape:\", trg.shape)\n",
    "    break\n",
    "\n",
    "# (2) Load láº¡i báº±ng cache (tá»± Ä‘á»™ng load tá»« file .pkl náº¿u cÃ³)\n",
    "train_loader, train_dataset = get_loader_cached(\"data/train.en.gz\", \"data/train.fr.gz\", batch_size=4)\n",
    "\n",
    "for src, trg in train_loader:\n",
    "    print(\"SRC shape:\", src.shape)\n",
    "    print(\"TRG shape:\", trg.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818c1996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Building English dataset from scratch...\n",
      "ðŸ’¾ Saved English cache: cache\\train_en_gz.pkl\n",
      "ðŸš€ Building French dataset from scratch...\n",
      "ðŸ’¾ Saved French cache: cache\\train_fr_gz.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29000/29000 [00:00<00:00, 52622.69it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29000/29000 [00:00<00:00, 50953.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC shape: torch.Size([4, 20])\n",
      "TRG shape: torch.Size([4, 23])\n"
     ]
    }
   ],
   "source": [
    "from src.dataset import get_loader_cached\n",
    "\n",
    "train_loader, train_dataset = get_loader_cached(\n",
    "    \"data/train.en.gz\", \"data/train.fr.gz\", batch_size=4\n",
    ")\n",
    "\n",
    "for src, trg in train_loader:\n",
    "    print(\"SRC shape:\", src.shape)\n",
    "    print(\"TRG shape:\", trg.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6268d0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Building English dataset from scratch...\n",
      "ðŸ’¾ Saved English cache: cache\\train_en_gz.pkl\n",
      "ðŸš€ Building French dataset from scratch...\n",
      "ðŸ’¾ Saved French cache: cache\\train_fr_gz.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29000/29000 [00:01<00:00, 28112.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29000/29000 [00:01<00:00, 22340.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC shape: torch.Size([4, 17])\n",
      "TRG shape: torch.Size([4, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.dataset import get_loader_cached\n",
    "\n",
    "train_loader, train_dataset = get_loader_cached(\n",
    "    \"data/train.en.gz\", \"data/train.fr.gz\", batch_size=4, shuffle=False\n",
    ")\n",
    "\n",
    "for src, trg in train_loader:\n",
    "    print(\"SRC shape:\", src.shape)\n",
    "    print(\"TRG shape:\", trg.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27dd03c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "2\n",
      "Pháº§n tá»­ 0: type=<class 'list'>\n",
      "Sample: [['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.'], ['several', 'men', 'in', 'hard', 'hats', 'are', 'operating', 'a', 'giant', 'pulley', 'system', '.'], ['a', 'little', 'girl', 'climbing', 'into', 'a', 'wooden', 'playhouse', '.']]\n",
      "Pháº§n tá»­ 1: type=<class 'src.dataset.Vocab'>\n",
      "Value: <src.dataset.Vocab object at 0x000002550C9883E0>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = \"cache/train_en_gz.pkl\"\n",
    "\n",
    "with open(file_path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(type(data))        # tuple\n",
    "print(len(data))         # sá»‘ pháº§n tá»­ trong tuple\n",
    "\n",
    "# In kiá»ƒu dá»¯ liá»‡u vÃ  má»™t vÃ i pháº§n tá»­ cá»§a tá»«ng pháº§n tá»­\n",
    "for i, part in enumerate(data):\n",
    "    print(f\"Pháº§n tá»­ {i}: type={type(part)}\")\n",
    "    if isinstance(part, (list, tuple)):\n",
    "        print(\"Sample:\", part[:3])  # in 5 pháº§n tá»­ Ä‘áº§u náº¿u lÃ  list/tuple\n",
    "    else:\n",
    "        print(\"Value:\", part)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a614e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample sentences ===\n",
      "two young , white males are outside near many bushes .\n",
      "several men in hard hats are operating a giant pulley system .\n",
      "a little girl climbing into a wooden playhouse .\n",
      "\n",
      "=== Sample vocab ===\n",
      "['<pad>', '<sos>', '<eos>', '<unk>', 'two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.', 'several', 'men', 'in', 'hard', 'hats']\n"
     ]
    }
   ],
   "source": [
    "sentences, vocab = data\n",
    "\n",
    "print(\"=== Sample sentences ===\")\n",
    "for s in sentences[:3]:\n",
    "    print(\" \".join(s))\n",
    "\n",
    "print(\"\\n=== Sample vocab ===\")\n",
    "print(vocab.itos[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247de8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
